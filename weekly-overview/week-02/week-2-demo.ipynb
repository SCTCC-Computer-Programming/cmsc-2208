{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 2 Demo\n",
        "\n",
        "This page builds a tiny student-performance dataset to demonstrate the core ideas Chapter 2 introduces.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attendance</th>\n",
              "      <th>homework_rate</th>\n",
              "      <th>quiz_avg</th>\n",
              "      <th>exam_avg</th>\n",
              "      <th>final_score</th>\n",
              "      <th>pass_fail</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>94</td>\n",
              "      <td>75</td>\n",
              "      <td>64</td>\n",
              "      <td>44</td>\n",
              "      <td>56.0</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>86</td>\n",
              "      <td>80</td>\n",
              "      <td>92</td>\n",
              "      <td>58</td>\n",
              "      <td>73.0</td>\n",
              "      <td>pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>80</td>\n",
              "      <td>99</td>\n",
              "      <td>73</td>\n",
              "      <td>69</td>\n",
              "      <td>76.0</td>\n",
              "      <td>pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>71</td>\n",
              "      <td>87</td>\n",
              "      <td>42</td>\n",
              "      <td>65</td>\n",
              "      <td>62.0</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72</td>\n",
              "      <td>82</td>\n",
              "      <td>86</td>\n",
              "      <td>64</td>\n",
              "      <td>74.0</td>\n",
              "      <td>pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>61</td>\n",
              "      <td>77</td>\n",
              "      <td>84</td>\n",
              "      <td>41</td>\n",
              "      <td>61.0</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>63</td>\n",
              "      <td>78</td>\n",
              "      <td>91</td>\n",
              "      <td>40</td>\n",
              "      <td>63.0</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>60</td>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>47</td>\n",
              "      <td>58.0</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>67</td>\n",
              "      <td>64</td>\n",
              "      <td>45</td>\n",
              "      <td>40</td>\n",
              "      <td>46.0</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>93</td>\n",
              "      <td>91</td>\n",
              "      <td>92</td>\n",
              "      <td>80</td>\n",
              "      <td>86.0</td>\n",
              "      <td>pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>86</td>\n",
              "      <td>84</td>\n",
              "      <td>41</td>\n",
              "      <td>72</td>\n",
              "      <td>65.0</td>\n",
              "      <td>fail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>97</td>\n",
              "      <td>50</td>\n",
              "      <td>73</td>\n",
              "      <td>79</td>\n",
              "      <td>71.0</td>\n",
              "      <td>pass</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    attendance  homework_rate  quiz_avg  exam_avg  final_score pass_fail\n",
              "0           94             75        64        44         56.0      fail\n",
              "1           86             80        92        58         73.0      pass\n",
              "2           80             99        73        69         76.0      pass\n",
              "3           71             87        42        65         62.0      fail\n",
              "4           72             82        86        64         74.0      pass\n",
              "5           61             77        84        41         61.0      fail\n",
              "6           63             78        91        40         63.0      fail\n",
              "7           60             97        50        47         58.0      fail\n",
              "8           67             64        45        40         46.0      fail\n",
              "9           93             91        92        80         86.0      pass\n",
              "10          86             84        41        72         65.0      fail\n",
              "11          97             50        73        79         71.0      pass"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "n = 12\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"attendance\": rng.integers(60, 101, n),\n",
        "    \"homework_rate\": rng.integers(50, 101, n),\n",
        "    \"quiz_avg\": rng.integers(40, 101, n),\n",
        "    \"exam_avg\": rng.integers(40, 101, n),\n",
        "})\n",
        "\n",
        "# numeric target (regression)\n",
        "df[\"final_score\"] = (0.2*df[\"homework_rate\"] + 0.3*df[\"quiz_avg\"] + 0.5*df[\"exam_avg\"]).round(0)\n",
        "\n",
        "# categorical target (classification)\n",
        "df[\"pass_fail\"] = np.where(df[\"final_score\"] >= 70, \"pass\", \"fail\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loading the tools we need**\n",
        "\n",
        "The first two lines load two libraries:\n",
        "\n",
        "-   **NumPy (`np`)**: used here for generating random numbers and doing simple numeric operations.\n",
        "-   **pandas (`pd`)**: used to create and display a table called a **DataFrame** (think: spreadsheet in Python).\n",
        "\n",
        "**Making the randomness repeatable**\n",
        "\n",
        "Next, the cell creates a random number generator:\n",
        "\n",
        "-   `rng` is a “random number generator” object we’ll use to create fake attendance and scores.\n",
        "-   The `0` is a **seed**, which makes the results repeatable. That means if you run the notebook again, you’ll get the same random dataset each time (useful for teaching and debugging).\n",
        "\n",
        "**Choosing how many students to generate**\n",
        "\n",
        "-   `n = 12` means we’re generating **12 rows**, so our dataset will represent 12 students.\n",
        "-   If we changed `n` to 100, we’d generate 100 students instead.\n",
        "\n",
        "**Building the DataFrame (our dataset table)**\n",
        "\n",
        "The `DataFrame` is created with four columns that represent **student features** (inputs):\n",
        "\n",
        "-   `attendance`\n",
        "-   `homework_rate`\n",
        "-   `quiz_avg`\n",
        "-   `exam_avg`\n",
        "\n",
        "Each column is filled with random whole numbers in a chosen range. Those ranges are just meant to look realistic (for example, attendance between about 60 and 100).\n",
        "\n",
        "So at this point:\n",
        "\n",
        "-   each **row** = one student\n",
        "-   each **column** = one measured input about that student\n",
        "\n",
        "**Creating a numeric target for regression**\n",
        "\n",
        "Next the cell creates a new column: and \\* `final_score` is calculated as a **weighted combination** of homework, quizzes, and exams. \\* This is meant to imitate how a course grade might be computed (exams count more than quizzes, etc.). \\* This column is a **number**, so it can be used as a **regression target** (predict a numeric value).\n",
        "\n",
        "**Creating a label target for classification**\n",
        "\n",
        "Then the cell creates another new column:\n",
        "\n",
        "-   `pass_fail` turns the numeric `final_score` into a **category label**: `\"pass\"` or `\"fail\"`.\n",
        "-   This column is a **classification target**, because the output must be one of a fixed set of options.\n",
        "\n",
        "**Displaying the result**\n",
        "\n",
        "The last line tells Jupyter/Quarto to display `df`, so you can see the dataset you just created as a table.\n",
        "\n",
        "In supervised learning, we organize our data in a table:\n",
        "\n",
        "-   Each **row** is one example (here, one student).\n",
        "-   The columns split into:\n",
        "    -   **X (features):** the input information we use to make a prediction\\\n",
        "        (`attendance`, `homework_rate`, `quiz_avg`, `exam_avg`)\n",
        "    -   **y (target/label):** the output we want to predict\n",
        "\n",
        "In our demo, we keeping **X** the same, and we show two choices for **y**:\n",
        "\n",
        "-   `pass_fail` is a **classification** target (the model chooses a label from {pass, fail})\n",
        "-   `final_score` is a **regression** target (the model predicts a numeric value)\n",
        "\n",
        "## Review the Difference in Targets\n",
        "\n",
        "This section zooms in on the **target column** for classification: `pass_fail`. The goal is to make the idea of a *classification target* visible: it isn’t a wide range of numbers — it’s a **small set of labels**.\n",
        "\n",
        "### Classification target (labels)\n",
        "\n",
        "#### Counting how many of each label we have\n",
        "\n",
        "This first line counts how many students fall into each class:\n",
        "\n",
        "-   `df[\"pass_fail\"]` selects the `pass_fail` column from the DataFrame.\n",
        "\n",
        "-   `.value_counts()` counts how many times each label appears.\n",
        "\n",
        "-   The output should look like a small summary table showing something like:\n",
        "\n",
        "    -   how many students are `\"pass\"`\n",
        "    -   how many students are `\"fail\"`\n",
        "\n",
        "This is useful because classification targets often come in **classes**, and it helps to know whether your dataset has a reasonable spread of those classes (for example, not *all* pass and *none* fail)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"pass_fail\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Making the label counts visual with a bar chart\n",
        "\n",
        "The next cell turns those same counts into a picture.\n",
        "\n",
        "-   `import matplotlib.pyplot as plt` loads the plotting library we’ll use to draw the chart.\n",
        "\n",
        "-   `df[\"pass_fail\"].value_counts().plot(kind=\"bar\")` does two steps at once:\n",
        "\n",
        "    1.  it recomputes the counts of `\"pass\"` vs `\"fail\"`\n",
        "    2.  it plots them as a **bar chart**\n",
        "\n",
        "-   `plt.title(...)` adds a title so the chart clearly communicates what it represents.\n",
        "\n",
        "-   `plt.xlabel(\"label\")` labels the horizontal axis: the category names (`pass` and `fail`).\n",
        "\n",
        "-   `plt.ylabel(\"count\")` labels the vertical axis: how many students are in each category.\n",
        "\n",
        "-   `plt.show()` displays the plot.\n",
        "\n",
        "The key takeaway from this plot: a **classification target** is made up of **labels** from a fixed set of options, and we can summarize it by counting how many examples fall into each label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df[\"pass_fail\"].value_counts().plot(kind=\"bar\")\n",
        "plt.title(\"Classification target: pass/fail\")\n",
        "plt.xlabel(\"label\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we’ve looked at the classification target as label counts, we’ll look at the regression target as numeric values.\n",
        "\n",
        "### Regression target (numeric)\n",
        "\n",
        "This next cell looks at the regression target column: `final_score`. The goal is to show that regression targets are **numeric values**, so we summarize them using numeric statistics and distributions.\n",
        "\n",
        "#### A quick numeric summary (`describe`)\n",
        "\n",
        "The first line:\n",
        "\n",
        "-   selects the `final_score` column\n",
        "-   produces a standard summary of numeric data\n",
        "\n",
        "The output includes common summary statistics like:\n",
        "\n",
        "-   how many values there are (`count`)\n",
        "-   the average (`mean`)\n",
        "-   spread (`std`)\n",
        "-   minimum and maximum (`min`, `max`)\n",
        "-   and percentile cutoffs (like 25%, 50%, 75%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"final_score\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### A histogram to show the distribution of scores\n",
        "\n",
        "The next cell visualizes the same column as a histogram.\n",
        "\n",
        "-   The histogram groups numeric values into bins (ranges) and counts how many students fall into each range.\n",
        "-   `bins=8` controls how many ranges the score axis is divided into. More bins means narrower ranges; fewer bins means wider ranges.\n",
        "\n",
        "Then the plot labels make it readable:\n",
        "\n",
        "-   the title explains what you’re looking at\n",
        "-   the x-axis label (“score”) tells you the values are numeric\n",
        "-   the y-axis label (“count”) tells you we’re counting how many students fall into each score range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"final_score\"].plot(kind=\"hist\", bins=8)\n",
        "plt.title(\"Regression target: final score\")\n",
        "plt.xlabel(\"score\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generalization: Train vs Test Split\n",
        "\n",
        "This section sets up the train/test split so we can check whether a model would work on new students, not just the students in our dataset. We do that by holding back some rows as a test set and using the rest as a training set. By the end of this section, you’ll have X_train, X_test, y_train, and y_test—two groups of students that let us measure generalization later.\n",
        "\n",
        "#### Step 1: Choose X (features) and y (target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X = input features (what we use to predict)\n",
        "X = df[[\"attendance\", \"homework_rate\", \"quiz_avg\", \"exam_avg\"]]\n",
        "\n",
        "# y = target (what we want to predict)\n",
        "y = df[\"pass_fail\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importing the split tool**\n",
        "\n",
        "-   `from sklearn.model_selection import train_test_split` imports a helper function from scikit-learn.\n",
        "-   We’ll use it to split our rows into a training set and a test set in a consistent way.\n",
        "\n",
        "**Defining X (features)**\n",
        "\n",
        "-   `X = df[[...]]` selects the feature columns from the DataFrame.\n",
        "\n",
        "-   We are choosing the same four inputs we’ve been using throughout the demo:\n",
        "\n",
        "    -   `attendance`\n",
        "    -   `homework_rate`\n",
        "    -   `quiz_avg`\n",
        "    -   `exam_avg`\n",
        "\n",
        "This creates a new table `X` that contains only the input information.\n",
        "\n",
        "**Defining y (target)**\n",
        "\n",
        "-   `y = df[\"pass_fail\"]` selects the target column we want to predict.\n",
        "-   Here we are choosing **classification** as our task, so `y` is the label column (`pass` or `fail`).\n",
        "\n",
        "At this point, we have separated the dataset into:\n",
        "\n",
        "-   **X:** what we use to predict\n",
        "-   **y:** what we want to predict\n",
        "\n",
        "#### Step 2: Split the rows into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=0\n",
        ")\n",
        "\n",
        "print(\"Total rows:\", len(df))\n",
        "print(\"Training rows:\", len(X_train))\n",
        "print(\"Test rows:\", len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Splitting X and y together**\n",
        "\n",
        "-   `train_test_split(X, y, ...)` splits the dataset into two groups of rows.\n",
        "-   We split **X and y at the same time** so that each feature row stays matched with its correct label.\n",
        "\n",
        "**This gives us four outputs:**\n",
        "\n",
        "-   `X_train`: the feature rows in the training set\n",
        "-   `X_test`: the feature rows in the test set\n",
        "-   `y_train`: the labels that go with the training rows\n",
        "-   `y_test`: the labels that go with the test rows\n",
        "\n",
        "**Choosing how large the test set is**\n",
        "\n",
        "-   `test_size=0.25` means **25% of the rows** go into the test set.\n",
        "-   With 12 total students, this will usually mean about 3 students in the test set and 9 in training.\n",
        "\n",
        "**Making the split repeatable**\n",
        "\n",
        "-   `random_state=0` makes the split repeatable.\n",
        "-   Without it, the split could change each time you run the notebook, which makes it harder to compare results.\n",
        "\n",
        "**Printing the sizes**\n",
        "\n",
        "The `print(...)` lines show how many rows ended up in each group so you can confirm the split happened.\n",
        "\n",
        "\n",
        "\n",
        "## kNN\n",
        "\n",
        "Now that we have a **training set** and a **test set**, we can train a model on the training students and see how well it generalizes to the test students.\n",
        "\n",
        "We’ll use **k-nearest neighbors (kNN)** for classification. kNN predicts the label for a new student by finding the **k closest** students in the training set and using a majority vote. Changing **k** changes how flexible the model is.\n",
        "\n",
        "### Step 1: Train one kNN model and check train vs test performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"Training accuracy:\", knn.score(X_train, y_train))\n",
        "print(\"Test accuracy:\", knn.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* `KNeighborsClassifier(...)` creates a kNN classifier.\n",
        "* `n_neighbors=3` sets **k = 3**, meaning the model looks at the 3 nearest training students when it predicts a label.\n",
        "* `knn.fit(X_train, y_train)` trains the model using the training set.\n",
        "\n",
        "  * For kNN, “training” mostly means storing the training data so the model can look up neighbors later.\n",
        "* `knn.score(...)` reports accuracy: the fraction of predictions that match the true labels.\n",
        "\n",
        "  * The **training accuracy** is how well it predicts the training students.\n",
        "  * The **test accuracy** is how well it predicts the held-back test students.\n",
        "\n",
        "This is our first concrete look at **generalization**: test accuracy is the estimate of how well this model works on new students.\n",
        "\n",
        "### Step 2: Watch what happens when we change k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "max_k = len(X_train)  # k can't be bigger than the number of training rows\n",
        "ks = range(1, max_k + 1)\n",
        "\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for k in ks:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    train_scores.append(knn.score(X_train, y_train))\n",
        "    test_scores.append(knn.score(X_test, y_test))\n",
        "\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"k\": list(ks),\n",
        "    \"train_acc\": train_scores,\n",
        "    \"test_acc\": test_scores\n",
        "})\n",
        "results.round(3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Importing the model**\n",
        "\n",
        "* `from sklearn.neighbors import KNeighborsClassifier` imports the kNN classification model from scikit-learn.\n",
        "* We import it inside this cell so the cell works even if it’s run on its own.\n",
        "\n",
        "**Choosing the k values we’re allowed to test**\n",
        "\n",
        "* `max_k = len(X_train)` gets the number of rows in the training set.\n",
        "* For kNN, `k` cannot be larger than the number of training examples, because the model can’t look for “10 nearest neighbors” if you only have 9 training students.\n",
        "* `ks = range(1, max_k + 1)` creates the list of k values we’ll test.\n",
        "  If `max_k` is 9, then this produces k values from 1 through 9.\n",
        "\n",
        "**Creating containers to store our results**\n",
        "\n",
        "* `train_scores = []` creates an empty list that will store training accuracy for each k.\n",
        "* `test_scores = []` creates an empty list that will store test accuracy for each k.\n",
        "\n",
        "These lists start empty, and we’ll fill them as we loop.\n",
        "\n",
        "**Looping over k values**\n",
        "\n",
        "* `for k in ks:` starts a loop.\n",
        "  That means we will run the indented code once for each k value.\n",
        "\n",
        "Inside the loop:\n",
        "\n",
        "* `knn = KNeighborsClassifier(n_neighbors=k)` creates a new kNN model using the current k value.\n",
        "* `knn.fit(X_train, y_train)` trains the model on the training set. For kNN, this mainly means the model stores the training data so it can compare new points to it later.\n",
        "* `train_scores.append(knn.score(X_train, y_train))` calculates accuracy on the training set and adds it to the `train_scores` list.\n",
        "* `test_scores.append(knn.score(X_test, y_test))` calculates accuracy on the test set and adds it to the `test_scores` list.\n",
        "\n",
        "So after the loop finishes:\n",
        "\n",
        "* `train_scores[i]` is the training accuracy for `k = ks[i]`\n",
        "* `test_scores[i]` is the test accuracy for `k = ks[i]`\n",
        "\n",
        "**Displaying the results**\n",
        "\n",
        "*  We build a small table called `results` with three columns: `k`, `train_acc`, and `test_acc`.\n",
        "* `pd.DataFrame({...})` creates the table by lining up each k value with its training accuracy and test accuracy.\n",
        "* `results.round(3)` rounds the accuracy values to three decimals so the table is easier to read.\n",
        "* The final line displays the table so we can quickly compare training vs test accuracy for each k before plotting.\n",
        "\n",
        "At this stage, the important thing is not the exact numbers—it’s that we now have a way to compare training performance vs test performance as k changes.\n",
        "\n",
        "\n",
        "### Step 3: Plot train vs test accuracy as k changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(list(ks), train_scores, label=\"training accuracy\")\n",
        "plt.plot(list(ks), test_scores, label=\"test accuracy\")\n",
        "plt.xlabel(\"k (number of neighbors)\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"kNN: training vs test accuracy as k changes\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Plotting the training accuracy line**\n",
        "\n",
        "* `plt.plot(list(ks), train_scores, label=\"training accuracy\")` draws a line graph of training accuracy.\n",
        "* `list(ks)` provides the x-values (the k values we tested).\n",
        "* `train_scores` provides the y-values (the training accuracy for each k).\n",
        "* `label=\"training accuracy\"` gives this line a name so it can appear in the legend.\n",
        "\n",
        "**Plotting the test accuracy line**\n",
        "\n",
        "* `plt.plot(list(ks), test_scores, label=\"test accuracy\")` draws a second line on the same plot for test accuracy.\n",
        "* It uses the same x-values (`k`), but a different set of y-values (`test_scores`).\n",
        "* This lets us compare training and test performance at the same k values.\n",
        "\n",
        "**Labeling the axes**\n",
        "\n",
        "* `plt.xlabel(\"k (number of neighbors)\")` labels the horizontal axis so it’s clear what the x-values represent.\n",
        "* `plt.ylabel(\"accuracy\")` labels the vertical axis so it’s clear we’re measuring accuracy (from 0 to 1).\n",
        "\n",
        "**Adding a title**\n",
        "\n",
        "* `plt.title(\"kNN: training vs test accuracy as k changes\")` adds a title that summarizes what the plot is showing.\n",
        "\n",
        "**Adding a legend**\n",
        "\n",
        "* `plt.legend()` displays a legend box that matches each line to its label (“training accuracy” vs “test accuracy”).\n",
        "* Without this, you’d see two lines but wouldn’t know which is which.\n",
        "\n",
        "**Displaying the plot**\n",
        "\n",
        "* `plt.show()` tells Python to render the chart.\n",
        "\n",
        "This plot is valuable because it shows how changing **k** changes model behavior:\n",
        "\n",
        "* When **k is small**, the model can fit the training data very closely, so training accuracy is often high.\n",
        "* As **k increases**, the model becomes less flexible, so training accuracy usually drops.\n",
        "* The test accuracy is the estimate of **generalization**, and we watch how it changes as k changes.\n",
        "\n",
        "Because our dataset is tiny, the test line may jump around, but the key idea still holds: **k controls how complex the model is**, and training vs test accuracy helps us see overfitting vs underfitting.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
